{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/Simple_Transformer_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfaGYwr6QGl0"},"outputs":[],"source":["!pip install transformers # From huggingface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SKOHXyzNQ5Wa"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n","model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", output_hidden_states=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"zdQBaZZcQ_Sa","outputId":"4cc3dbf5-922d-4eda-b47e-75e8adbc96e2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"name":"stdout","output_type":"stream","text":["\n"," The Shawshank Redemption\n"]}],"source":["text = \"The Shawshank\"\n","\n","# Tokenize the input string\n","input = tokenizer.encode(text, return_tensors=\"pt\")\n","\n","# Run the model\n","output = model.generate(input, max_length=5, do_sample=False)\n","\n","# Print the output\n","print('\\n',tokenizer.decode(output[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"m8m1rK3gNNW4","outputId":"61da2785-cd28-4b00-84bf-ac65deea8d57"},"outputs":[{"data":{"text/plain":["tensor([[  464, 18193,  1477,   962, 34433]])"]},"execution_count":101,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Print the token ides (of the input and output)\n","output"]},{"cell_type":"markdown","metadata":{"id":"tProbSeTJATA"},"source":["## From words to vectors and back"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"Dy2Pjd--ROa5","outputId":"1227d405-a6b1-48bd-f6e6-127ea739cc04"},"outputs":[{"data":{"text/plain":["tensor([[  464, 18193,  1477,   962]])"]},"execution_count":102,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Print the input token ids\n","text = \"The Shawshank\"\n","input = tokenizer(text, return_tensors=\"pt\")['input_ids']\n","input"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"sTGffdCOJbdo","outputId":"e45abbde-d575-40bb-82b8-48dc2c90ffb3"},"outputs":[{"data":{"text/plain":["['The', 'Ä Shaw', 'sh', 'ank']"]},"execution_count":91,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["tokenizer.convert_ids_to_tokens(input[0])"]},{"cell_type":"markdown","metadata":{"id":"4lbn94y0P2UV"},"source":["## Breathe meaning into numbers (Embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"5QCFBcxZQIN8","outputId":"78f4012c-3c7c-4c89-813a-62abae5cd98d"},"outputs":[{"data":{"text/plain":["Embedding(50257, 768)"]},"execution_count":95,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# This is the embedding matrix of the model\n","model.transformer.wte # Dimensions are: (Number of tokens in vocabulary, dimension of model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ah9tc1gP7lX"},"outputs":[],"source":["# Get the embedding vector of token # 464 ('The')\n","model.transformer.wte(torch.tensor(464))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"ZT5lmGVK60mJ","outputId":"3c82374f-eee5-4e19-ef64-e0908b5719ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"name":"stdout","output_type":"stream","text":["\n"," The chicken didn't cross the road because it was in the street. The driver then asked if the\n"]}],"source":["text = \"The chicken didn't cross the road because it was\"\n","\n","# Tokenize the input string\n","input = tokenizer.encode(text, return_tensors=\"pt\")\n","\n","# Run the model\n","output = model.generate(input, max_length=20, do_sample=True)\n","\n","# Print the output\n","print('\\n',tokenizer.decode(output[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BstYQU6NkkDA"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}